{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imvNzJyOwBxb",
        "outputId": "2907dc74-9247-4de7-8455-4389abdfdff5"
      },
      "outputs": [],
      "source": [
        "# This script was run in a Google Colab environment.\n",
        "\n",
        "!pip install -q transformers  evaluate\n",
        "!pip install -U datasets\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmvELeWkwT8p",
        "outputId": "897fd084-4cf4-48aa-d00d-efc186751253"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dZxOZacwme4"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"json\", data_files={\n",
        "    \"train\": \"/content/drive/MyDrive/cuad_project/cuad_qa_train.json\",\n",
        "    \"validation\": \"/content/drive/MyDrive/cuad_project/cuad_qa_test.json\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364,
          "referenced_widgets": [
            "6d0c9205c3394122ae45c90aafb2ab68",
            "47a407a9f9244c758de24ce2c3598526",
            "cc04276c56ec4f98aea3f3e7943cbbed",
            "ccbe69c4b48f43e9acb5d8024e252489",
            "9305d7fa2e1344d0bc502dd8c7a17bd9",
            "e0222e8ccc7b44c0a65d796783dcef9c",
            "50de25ff6bbf436cbc133ab872d08f58",
            "9e1b5cbacfa445f99ce2c14aac0c303d",
            "5032a546b7ae4e7cb9aa3a2e67de2101",
            "328e7f1d047543c6a9ee535ada1920ba",
            "b40c75fea4104bf7afb2e3643fb5511e"
          ]
        },
        "id": "-HwQ7Tcgx-qG",
        "outputId": "4bbbfe9e-ab2c-49a9-db52-7f137805abf1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForQuestionAnswering,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    TrainerCallback,\n",
        ")\n",
        "from datasets import load_dataset, DatasetDict\n",
        "import evaluate\n",
        "import random\n",
        "\n",
        "# === Load CUAD-style dataset from JSON\n",
        "dataset = load_dataset(\"json\", data_files={\n",
        "    \"train\": \"/content/drive/MyDrive/cuad_project/cuad_qa_train.json\",\n",
        "    \"validation\": \"/content/drive/MyDrive/cuad_project/cuad_qa_test.json\"\n",
        "})\n",
        "\n",
        "print(\"✅ Dataset loaded:\", dataset)\n",
        "print(\"🧪 Train size:\", len(dataset[\"train\"]), \"| Val size:\", len(dataset[\"validation\"]))\n",
        "\n",
        "# === Load tokenizer and model\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# === Preprocessing with overflow and keeping answers\n",
        "def preprocess(example):\n",
        "    tokenized = tokenizer(\n",
        "        example[\"question\"],\n",
        "        example[\"context\"],\n",
        "        truncation=\"only_second\",\n",
        "        padding=\"max_length\",\n",
        "        max_length=384,\n",
        "        stride=128,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    sample_count = len(tokenized[\"input_ids\"])\n",
        "\n",
        "    # Repeat other fields to match length\n",
        "    tokenized[\"answers\"] = [example[\"answers\"]] * sample_count\n",
        "    tokenized[\"context\"] = [example[\"context\"]] * sample_count\n",
        "    tokenized[\"question\"] = [example[\"question\"]] * sample_count\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess, batched=True)\n",
        "\n",
        "# === Span alignment\n",
        "def add_token_positions(example):\n",
        "    start_char = example[\"answers\"][\"answer_start\"]\n",
        "    end_char = start_char + len(example[\"answers\"][\"text\"])\n",
        "    offsets = example[\"offset_mapping\"]\n",
        "\n",
        "    start_token = end_token = None\n",
        "    for idx, (s, e) in enumerate(offsets):\n",
        "        if s <= start_char < e:\n",
        "            start_token = idx\n",
        "        if s < end_char <= e:\n",
        "            end_token = idx\n",
        "            break\n",
        "\n",
        "    if start_token is None or end_token is None:\n",
        "        return {}  # skip\n",
        "    example[\"start_positions\"] = start_token\n",
        "    example[\"end_positions\"] = end_token\n",
        "    return example\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.map(add_token_positions, batched=False)\n",
        "\n",
        "# === Filter and cleanup\n",
        "tokenized_dataset = tokenized_dataset.filter(lambda ex: \"start_positions\" in ex and \"end_positions\" in ex)\n",
        "tokenized_dataset = tokenized_dataset.remove_columns([\"offset_mapping\", \"answers\"])\n",
        "\n",
        "# === Evaluation metrics\n",
        "squad_metric = evaluate.load(\"squad\")\n",
        "def compute_metrics(eval_pred):\n",
        "    start_logits, end_logits = eval_pred.predictions\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    for i, example in enumerate(tokenized_dataset[\"validation\"]):\n",
        "        input_ids = example[\"input_ids\"]\n",
        "        start = torch.argmax(torch.tensor(start_logits[i])).item()\n",
        "        end = torch.argmax(torch.tensor(end_logits[i])).item()\n",
        "        if end < start:\n",
        "            end = start\n",
        "        pred_answer = tokenizer.decode(input_ids[start:end+1], skip_special_tokens=True)\n",
        "\n",
        "        predictions.append({\"id\": str(i), \"prediction_text\": pred_answer})\n",
        "        references.append({\"id\": str(i), \"answers\": {\"text\": [example[\"context\"][example['start_positions']:example['end_positions']]], \"answer_start\": [0]}})\n",
        "    return squad_metric.compute(predictions=predictions, references=references)\n",
        "\n",
        "# === Logging predictions after each epoch\n",
        "class PrintPredictionsCallback(TrainerCallback):\n",
        "    def on_evaluate(self, args, state, control, **kwargs):\n",
        "        print(\"\\n📝 Sample Predictions:\")\n",
        "        val_set = tokenized_dataset[\"validation\"]\n",
        "        indices = random.sample(range(len(val_set)), k=5)\n",
        "        for idx in indices:\n",
        "            ex = val_set[idx]\n",
        "            inputs = tokenizer(\n",
        "                ex[\"question\"],\n",
        "                ex[\"context\"],\n",
        "                truncation=\"only_second\",\n",
        "                max_length=384,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                start = torch.argmax(outputs.start_logits).item()\n",
        "                end = torch.argmax(outputs.end_logits).item()\n",
        "                if end < start:\n",
        "                    end = start\n",
        "                pred_answer = tokenizer.decode(inputs[\"input_ids\"][0][start:end+1], skip_special_tokens=True)\n",
        "\n",
        "            print(f\"\\n📌 Q: {ex['question']}\")\n",
        "            print(f\"🤖 Predicted: {pred_answer}\")\n",
        "            print(f\"✅ Ground Truth (tokens): {tokenizer.decode(ex['input_ids'][ex['start_positions']:ex['end_positions']+1], skip_special_tokens=True)}\")\n",
        "\n",
        "# === Training config\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"/content/cuad_roberta\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=100,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# === Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[PrintPredictionsCallback()]\n",
        ")\n",
        "\n",
        "# === Train!\n",
        "trainer.train()\n",
        "\n",
        "# === Save\n",
        "trainer.save_model(\"/content/drive/MyDrive/cuad_project/cuad_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/cuad_project/cuad_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sR9tyDJ5J6T",
        "outputId": "1d148dc2-6e27-47f9-b487-e68527f43120"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/cuad_project/cuad_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/cuad_project/cuad_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odjO8oSnz1ug",
        "outputId": "fc366baa-a94a-4f34-f6fb-f49fcc35fe63"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "# === Load test data ===\n",
        "with open(\"/content/drive/MyDrive/cuad_project/cuad_qa_test.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "# === Load trained model and tokenizer ===\n",
        "model_path = \"/content/drive/MyDrive/cuad_project/cuad_model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "model.eval()\n",
        "\n",
        "# === Clause extraction logic ===\n",
        "def extract_clause(question, context, model, tokenizer, max_length=512):\n",
        "    inputs = tokenizer(\n",
        "        question,\n",
        "        context,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    print(\"\\n🔍 Tokenized input (first 50 tokens):\")\n",
        "    print(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])[:50])\n",
        "    print(\"📏 Total input length:\", len(inputs[\"input_ids\"][0]))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    start = torch.argmax(outputs.start_logits).item()\n",
        "    end = torch.argmax(outputs.end_logits).item()\n",
        "\n",
        "    print(f\"\\n🔁 Predicted token span: {start} to {end}\")\n",
        "    print(\"🔢 Start logits (top 5):\", torch.topk(outputs.start_logits, 5).values.tolist())\n",
        "    print(\"🔢 End logits (top 5):\", torch.topk(outputs.end_logits, 5).values.tolist())\n",
        "\n",
        "    if start >= len(inputs[\"input_ids\"][0]) or end >= len(inputs[\"input_ids\"][0]):\n",
        "        return \"[Invalid span: out of bounds]\"\n",
        "    if end < start:\n",
        "        return \"[Invalid span: end before start]\"\n",
        "\n",
        "    tokens = inputs[\"input_ids\"][0][start:end + 1]\n",
        "    return tokenizer.decode(tokens, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "# === Choose contract ID (trimmed) ===\n",
        "contract_id = \"DovaPharmaceuticalsInc_20181108_10-Q_EX-10.2_11414857_EX-10.2_Promotion Agreement\"\n",
        "\n",
        "# === Filter questions for this contract ===\n",
        "contract_entries = [e for e in test_data if e[\"id\"].startswith(contract_id)]\n",
        "print(f\"\\n📄 Found {len(contract_entries)} questions for contract: {contract_id}\\n\")\n",
        "\n",
        "if not contract_entries:\n",
        "    print(\"⚠️ No entries found. Check contract_id formatting.\")\n",
        "    exit()\n",
        "\n",
        "# === Show clause types\n",
        "for i, e in enumerate(contract_entries):\n",
        "    print(f\"{i + 1}. {e['id'].split('__')[-1]}\")\n",
        "\n",
        "# === Choose one to evaluate\n",
        "q_index = int(input(\"\\n🎯 Choose a question index to run (1-based): \")) - 1\n",
        "question = contract_entries[q_index][\"question\"]\n",
        "context = contract_entries[q_index][\"context\"]\n",
        "\n",
        "print(\"\\n🧠 Question:\")\n",
        "print(question)\n",
        "\n",
        "print(\"\\n📜 Context (first 500 chars):\")\n",
        "print(context[:500])\n",
        "\n",
        "# === Model inference\n",
        "answer = extract_clause(question, context, model, tokenizer)\n",
        "\n",
        "# === Output results\n",
        "print(\"\\n🤖 Model's Answer:\")\n",
        "print(answer)\n",
        "\n",
        "print(\"\\n✅ Ground Truth:\")\n",
        "gt_answer = contract_entries[q_index].get(\"answers\", {}).get(\"text\", \"[No labeled answer]\")\n",
        "print(gt_answer)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "328e7f1d047543c6a9ee535ada1920ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a407a9f9244c758de24ce2c3598526": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0222e8ccc7b44c0a65d796783dcef9c",
            "placeholder": "​",
            "style": "IPY_MODEL_50de25ff6bbf436cbc133ab872d08f58",
            "value": "Map:   0%"
          }
        },
        "5032a546b7ae4e7cb9aa3a2e67de2101": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50de25ff6bbf436cbc133ab872d08f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d0c9205c3394122ae45c90aafb2ab68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47a407a9f9244c758de24ce2c3598526",
              "IPY_MODEL_cc04276c56ec4f98aea3f3e7943cbbed",
              "IPY_MODEL_ccbe69c4b48f43e9acb5d8024e252489"
            ],
            "layout": "IPY_MODEL_9305d7fa2e1344d0bc502dd8c7a17bd9"
          }
        },
        "9305d7fa2e1344d0bc502dd8c7a17bd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e1b5cbacfa445f99ce2c14aac0c303d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40c75fea4104bf7afb2e3643fb5511e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc04276c56ec4f98aea3f3e7943cbbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1b5cbacfa445f99ce2c14aac0c303d",
            "max": 2395,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5032a546b7ae4e7cb9aa3a2e67de2101",
            "value": 0
          }
        },
        "ccbe69c4b48f43e9acb5d8024e252489": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_328e7f1d047543c6a9ee535ada1920ba",
            "placeholder": "​",
            "style": "IPY_MODEL_b40c75fea4104bf7afb2e3643fb5511e",
            "value": " 0/2395 [00:00&lt;?, ? examples/s]"
          }
        },
        "e0222e8ccc7b44c0a65d796783dcef9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
